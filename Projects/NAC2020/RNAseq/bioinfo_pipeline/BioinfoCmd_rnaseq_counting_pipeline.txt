#!/bin/bash
#SBATCH --job-name="NAC_rnaseq"
#SBATCH --ntasks=2 --cpus-per-task=64
#SBATCH --mem=700G
#SBATCH --time=7-0:00:00
#SBATCH --mail-user=jscurll.ubc+VPC.SBATCH@gmail.com
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --error=tmp/Job.%J.err
#SBATCH --output=tmp/Job.%J.out



### !!!!!!!!!!!!!!!!!!!!!!!!!! ###
### !!!   IMPORTANT INFO   !!! ###
### !!!!!!!!!!!!!!!!!!!!!!!!!! ###

### Samples sequenced on different platforms should be processed separately
### if some used patterned flow cells and others did not or if some used
### Illumina two-colour chemistry and others did not. These differences result
### in some differences to user-specified parameters. CHECK ALL PARAMETERS
### CAREFULLY!



##############################
##############################
####                      ####
####    GLOBAL OPTIONS    ####
####                      ####
##############################
##############################



##########################################################################
##   Specify number of threads/cores to use for parallel computations   ##
##########################################################################


## Maximum number of separate processes to run for tasks that allow
## multithreading (e.g. Cutadapt and STAR).
## Copy the value of ntasks (for SBATCH job submission) from above here:

ntasks=2


## Number of threads/cores per task (i.e. *PER FILE*) to use for multithreading 
## of Cutadapt, STAR, etc.
## Copy the value of cpus-per-task (for SBATCH job submission) from above here:

nthreads_per_task=64


## Specify total number of threads to use.
## This should be equal to [ntasks * cpus-per-task] from SBATCH job submission.

nthreads=$(( ${ntasks} * ${nthreads_per_task} ))



#########################################################
##  Specify which step of the pipeline to start from.  ##
#########################################################

## StartingStep should be set equal to an integer between 1 and 8 inclusive.
## All pipeline steps from StartingStep onwards will be executed, while earlier
## steps will be skipped. For example, specifying StartingStep=5 here will
## assume that all of Steps 1 (Cutadapt) to 4 (read mapping by STAR) have already
## been executed and generated the directories and files required for Steps 5-8.
## The pipeline step numbers are as follows:
##    1 - Read trimming by Cutadapt;
##    2 - Concatenate fastq files from the same sample but different lanes;
##    3 - FastQC (QC for fastq);
##    4 - Align reads to genome using STAR (generates .bam files);
##    5 - Sort BAM files by coordinate and mark duplicates (Samtools);
##    6 - Qualimap (QC for bam);
##    7 - Count reads per gene (or other feature) using featureCounts;
##    8 - Generate aggregated QC report using MultiQC.

StartingStep=7



#################################################################################
##  Specify the path of the directory containing fastq files to be processed.  ##
#################################################################################

## DO NOT include the trailing slash at the end of the directory path.

fastq_dir="/groups/blackgrp/data/blacklab_data/NAC2020_RNAseq/AN00011754_RNAseq/fastq"



#####################################################
##  Specify the naming format of the fastq files.  ##
#####################################################

## Set nameFormat=FORMAT1, FORMAT2, FORMAT3, or FORMAT4.
##
## FORMAT1 means that the fastq file names end with "_R1_001.fastq.gz" for Read 1
## and "_R2_001.fastq.gz" for Read 2 in paired-end RNA-seq data. 
## 
## FORMAT2 is for .fastq.gz files generated by the BC GSC, whose names start with the
## flowcell name and specify the read number (1 or 2) in a read pair after the second
## underscore, before the sample barcode -- e.g. H7FTLCCX2_3_1_AAGTCGAG-CGCAATGT....fastq.gz
## for the Read-1 file and H7FTLCCX2_3_2_AAGTCGAG-CGCAATGT....fastq.gz for the corresponding
## Read-2 file. If fastq files are named according to FORMAT2, you must also specify here
## the prefix of the fastq file name that comes before the read number (minus the last
## underscore) -- e.g. namePrefix="H7FTLCCX2_3" -- and the suffix of the fastq file name
## that comes after the sample barcode (excluding the first underscore and the extension)
## -- e.g. "150bp_257247.concat_chastity_passed". If nameFormat is set to FORMAT1 or
## FORMAT3, then namePrefix and nameSuffix will be ignored.
##
## FORMAT3 is for fastq files that end with "_1.fastq" for Read 1 in PE RNA-seq data and
## end with "_2.fastq" for Read 2. FORMAT3 is the format for fastq files output by
## fastq-dump or fasterq-dump from the SRA toolkit.
##
## FORMAT4 is for .fastq.gz files of the form <sample_ID>_1<suffix>.fastq.gz for Read 1
## and <sample_ID>_2<suffix>.fastq.gz for Read 2 in paired-end RNA-seq data. FORMAT4 is
## similar to FORMAT2 but <sample_ID>, which could be the flowcell/lane, distinguishes the
## samples and <suffix> is a file name suffix (minus the .fastq.gz extension) that is the
## same for all samples and will be removed. For FORMAT4, nameSuffix must be specified here
## like for FORMAT2, but namePrefix is not required and will be ignored. Note that if the
## read number ("_1" or "_2") is immediately followed by an underscore, then this underscore
## must be included in nameSuffix for FORMAT4 (unlike for FORMAT2).

nameFormat=FORMAT4

namePrefix=""
nameSuffix=""



#######################################################################################
##  Specify the name of your conda environment in which all programs are installed.  ##
#######################################################################################

conda_env_name="rnaseq_env1"


###################################################
##  Specify the location of your conda.sh file.  ##
###################################################

## If you installed Anaconda 3 in the default location, then the conda.sh file should
## be located at ~/anaconda3/etc/profile.d/conda.sh

conda_path="~/anaconda3/etc/profile.d/conda.sh"



################################
################################
####                        ####
####    CUTADAPT OPTIONS    ####
####                        ####
################################
################################


## SPECIFY ADAPTER SEQUENCES TO TRIM FROM 3' ENDS OF PAIRED-END READS
##  See this link for details of Illumina adapter sequences that should be trimmed:
##  https://support.illumina.com/bulletins/2016/12/what-sequences-do-i-use-for-adapter-trimming.html

## READ-1 ADAPTER SEQUENCES TO TRIM.
## Specify in the format "-a NNNNNN -a XXXXXX" where NNNNNN and XXXXXX are different adapter sequences.
## Each adapter sequence to trim from Read 1 must be preceded by the "-a" flag, which tells Cutadapt
## that the following sequence should be trimmed from the 3' ends of R1 reads.

## Uncomment the next line for most Illumina TruSeq and ScriptSeq library prep kits.
R1_AdaptersToTrim="-a AGATCGGAAGAGCACACGTCTGAAC"

## Uncomment the next line for most Nextera, AmpliSeq and TruSight library prep kits.
#R1_AdaptersToTrim="-a CTGTCTCTTATACACATCT"

## Uncomment the next line to trim both types of adapter.
#R1_AdaptersToTrim="-a AGATCGGAAGAGCACACGTCTGAAC -a CTGTCTCTTATACACATCT"


## READ-2 ADAPTER SEQUENCES TO TRIM.
## Specify in the format "-A NNNNNN -A XXXXXX" where NNNNNN and XXXXXX are different adapter sequences.
## Each adapter sequence to trim from Read 2 must be preceded by the "-A" flag, which tells Cutadapt
## that the following sequence should be trimmed from the 3' ends of R2 reads.

## Uncomment the next line for most Illumina TruSeq and ScriptSeq library prep kits.
R2_AdaptersToTrim="-A AGATCGGAAGAGCGTCGTGTAGGGA"

## Uncomment the next line for most Nextera, AmpliSeq and TruSight library prep kits.
#R2_AdaptersToTrim="-A CTGTCTCTTATACACATCT"

## Uncomment the next line to trim both types of adapter.
#R2_AdaptersToTrim="-A AGATCGGAAGAGCGTCGTGTAGGGA -A CTGTCTCTTATACACATCT"


## Number of bases to cut from 3' end of reads before adapter trimming
CutBases=1


## Were the samples sequenced on an Illumina platform that uses two-colour
## chemistry? This includes NextSeq and NovaSeq.
## Set TwoColourChem=true if two-colour chemistry was used (e.g. NextSeq)
## or set TwoColourChem=false otherwise (e.g. HiSeq 2500).

TwoColourChem=true


## QUALITY CUT-OFF.
## Set a Q (PHRED quality score) threshold. Bases with Q below this threshold will be
## trimmed from the 3' end of reads before adapter trimming. Must be in the range
## 0 <= Q <= 40. Suggested: Q=5 or Q=10.

Q=10


## SET MINIMUM LENGTH OF READS TO KEEP AFTER TRIMMING
MinLength=24



############################
############################
####                    ####
####    STAR OPTIONS    ####
####                    ####
############################
############################


####################################################
##  Specify the max. read length after trimming.  ##
####################################################

## Specify the max read length in the data (raw read length minus minimum number of
## bases cut during read trimming). E.g. for 2 x 150 bp PE sequencing and adapter
## trimming with Cutadapt with 1 base trimmed from all reads before adapter trimming,
## use MaxReadLength=149.

MaxReadLength=150


############################################
##  Set reference genome and annotation.  ##
############################################


## Specify which reference genome assembly to align reads to.
## Currently available options are GRCh38 for human and GRCm38 for mouse.
## The case and spelling matter, therefore you must set RefGenome to be exactly either
## "GRCh38" (or "human") or "GRCm38" (or "mouse").

RefGenome="GRCh38"


## Specify SpikeIn="ERCC" if ERCC spike-in control sequences were added to the samples.
## If no spike-in controls were added, specify SpikeIn="".

SpikeIn="ERCC"
#SpikeIn=""


## Specify the directory (RefGenome_dir) and filename (RefGenome_fasta) of the ref genome
## primary assembly FASTA file. Also specify the full path (directory and filename together)
## of the ref genome annotation GTF file (annotationGTF). DO NOT include the trailing slash
## (/) at the end of the RefGenome_dir directory path.

RefGenome_dir="/groups/zoubeidigrp/genomes_and_transcriptomes/Reference_genomes_fasta"
RefAnnotation_dir="/groups/zoubeidigrp/genomes_and_transcriptomes/Reference_annotations"

if [[ "${RefGenome}" == "GRCh38" || "${RefGenome}" == "human" || "${RefGenome}" == "hg38" ]]
then
   ## Use this block of code for human GRCh38
    if [[ "${SpikeIn}" == "ERCC" ]]
    then
        RefGenome_fasta="Human/GENCODE/GRCh38.primary_assembly.genome.ERCC92.fa"
        annotationGTF="${RefAnnotation_dir}/Human/hg38.gencode.v39.primary_assembly.annotation.ERCC92.gtf"
    else
        RefGenome_fasta="Human/GENCODE/GRCh38.primary_assembly.genome.fa"
        annotationGTF="${RefAnnotation_dir}/Human/hg38.gencode.v39.primary_assembly.annotation.gtf"
    fi
elif [[ "${RefGenome}" == "GRCm38" || "${RefGenome}" == "mouse" ]]
then
   ## Use this block of code for mouse GRCm38
    if [[ "${SpikeIn}" == "ERCC" ]]
    then
        RefGenome_fasta="Mouse/GENCODE/GRCm38.primary_assembly.genome.ERCC92.fa"
        annotationGTF="${RefAnnotation_dir}/Mouse/gencode.vM25.primary_assembly.annotation.ERCC92.gtf"
    else
        RefGenome_fasta="Mouse/GENCODE/GRCm38.primary_assembly.genome.fa"
        annotationGTF="${RefAnnotation_dir}/Mouse/gencode.vM25.primary_assembly.annotation.gtf"
    fi
else
        echo "Invalid setting for RefGenome. Exiting."
        exit 1
fi


############################################################
##  Specify the directory for/of the STAR genome indexes  ##
############################################################

STAR_genomeDir="/groups/zoubeidigrp/genomes_and_transcriptomes/STAR_genome_indexes"

fa_basename=$(basename ${RefGenome_fasta})
gtf_basename=$(basename ${annotationGTF})
STAR_genomeDir="${STAR_genomeDir}/STAR_idx--${fa_basename}--${gtf_basename}--MaxReadLength${MaxReadLength}"



################################
################################
####                        ####
####    SAMTOOLS OPTIONS    ####
####                        ####
################################
################################


#######################################################################
##  Set the optical duplicate distance setting in Samtools markdup.  ##
#######################################################################

## This is the maximum distance (in pixels) for two called clusters on a flowcell
## to be considered as possible optical duplicates.
##
## Suggested settings are 100 for non-patterned flowcells (e.g. HiSeq 2500) and 2500
## for patterned flowcells (e.g. HiSeq X, HiSeq 4000, NovaSeq). Setting this to 0 
## means that Samtools markdup will NOT look for optical duplicates.

optical_dup_dist=2500


####################################################################
##  Additional options (flags) for samtools markdup as a string.  ##
####################################################################

## Specify a string containing extra options to pass to samtools markdup, other
## than options that are already hard-coded. Specify markdup_opts='' (an empty 
## string) for no additional options. The following options/flags are already
## passed to markdup and so MUST NOT be included here: -d, -c, -f, -O, -@, and
## --include-fails. Useful extra options to specify here are "--no-multi-dup" (to
## speed up optical duplicate marking by not checking duplicates of duplicates
## for correctness) and "--read-coords <REGEX>" for optical duplicate detection
## with non-standard read names.

markdup_opts='--no-multi-dup'



#####################################
#####################################
####                             ####
####    FEATURECOUNTS OPTIONS    ####
####                             ####
#####################################
#####################################


## Create a separate featureCounts output file for each input BAM file, or
## keep all samples aggregated in a single table with one column per sample?
##   Set separate_featureCounts=true to create separate files, or set
##   separate_featureCounts=false to put results for all samples in one table.
##   Note that "true" or "false" must be written in lowercase.

separate_featureCounts=false


## Specify a suffix (excluding file extension) to include in the featureCounts output 
## file name when aggregating all samples into a single featureCounts table. 
##
##    Use a sufffix that summarizes all samples when the feature counts for all
##    samples are output into a single file in which each column represents one
##    sample. Use outname_suffix="" to use no suffix, in which case the output 
##    feature counts matrix will be called "featureCounts_<RefGenome>.txt". Do not 
##    use a space or special characters such as -, +, =, $, *, &, #, @, etc. in the
##    suffix. Underscores (_) and periods (.) are acceptable characters. The suffix
##    specified here will follow immediately after the reference genome in the file
##    name without being automatically preceded by any underscores or periods;
##    therefore, you should include (for example) underscores at the start of the
##    suffix. 

outname_suffix=".BlackLab_NAC_2020_cohort"


###################################################
##  Specify OPTIONS for input to featureCounts.  ##
###################################################

## See http://manpages.org/featurecounts for featureCounts options.

opts="-F GTF -t exon -g gene_id -T ${nthreads_per_task} -p -C -d ${MinLength}"




#####################################################
#####################################################
####                                             ####
####  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ####
####  !!!!                                 !!!!  ####
####  !!!!  END OF USER-SPECIFIED OPTIONS  !!!!  ####
####  !!!!                                 !!!!  ####
####  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ####
####                                             ####
#####################################################
#####################################################




##################################
##################################
####                          ####
####    BEGIN MAIN PROGRAM    ####
####                          ####
##################################
##################################




##################################
##  Activate Conda environment  ##
##################################

source ~/.bashrc
sleep 2
wait

source ${conda_path}
sleep 2
wait

conda activate ${conda_env_name}
sleep 2
wait


## Check conda environment
printf "\n\nOutput of conda info:\n\n"
conda info
printf "\n\nOutput of conda list:\n\n"
conda list
printf "\n\n##################\n\n"
wait



################
##  CUTADAPT  ##
################

## Use the following command to install Cutadapt in a conda environment
##  conda install -c bioconda cutadapt

##  Change directory to directory containing fastq files
cd "${fastq_dir}"

## Determine CutAdapt output folder name
cutadapt_ver=$(cutadapt --version)
cutadapt_outdir="${fastq_dir}/cutadapt${cutadapt_ver}_3pCut${CutBases}q${Q}m${MinLength}"

## Create output directory if it doesn't already exist
if [ ! -d ${cutadapt_outdir} ]
then
        mkdir "${cutadapt_outdir}"
fi

if [[ "${nameFormat}" == "FORMAT1" ]]
then
        R1_fastq_list="${fastq_dir}/*R1_001.fastq.gz"
elif [[ "${nameFormat}" == "FORMAT2" ]]
then
        R1_fastq_list="${fastq_dir}/${namePrefix}_1_*${nameSuffix}.fastq.gz"
elif [[ "${nameFormat}" == "FORMAT3" ]]
then
        R1_fastq_list="${fastq_dir}/*_1.fastq"
elif [[ "${nameFormat}" == "FORMAT4" ]]
then
        R1_fastq_list="${fastq_dir}/*_1${nameSuffix}.fastq.gz"
else
        echo "Invalid setting for nameFormat. Exiting."
        exit 1
fi

## Determine whether to use the -q or --nextseq-trim option for quality
## trimming in Cutadapt.
if [ "${TwoColourChem}" = true ]
then
        quality_opt="--nextseq-trim $Q"
else
        quality_opt="-q $Q"
fi

if [ ${StartingStep} -le 1 ]; then  #### STEP 1 starts here

for i in ${R1_fastq_list}
do
        ## Trim the names of the input files (by removing .fastq.gz extension etc.)
        ## to create prefix for output file names. Also construct the names of the
        ## input Read-1 and Read-2 fastq files.
        if [[ "${nameFormat}" == "FORMAT1" ]]
        then
            prefix=$(basename --suffix=".fastq.gz" $i | sed "s/_R[12]_001//")
            R1fastq="${fastq_dir}/${prefix}_R1_001.fastq.gz"
            R2fastq="${fastq_dir}/${prefix}_R2_001.fastq.gz"
        elif [[ "${nameFormat}" == "FORMAT2" ]]
        then
            prefix=$(basename --suffix="_${nameSuffix}.fastq.gz" $i \
                     | sed -r "s/${namePrefix}_1_/${namePrefix}_/" )
            R1fastq=$i
            R2fastq=$(ls $i | sed -r "s/${namePrefix}_1_/${namePrefix}_2_/")
        elif [[ "${nameFormat}" == "FORMAT3" ]]
        then
            prefix=$(basename --suffix="_1.fastq" $i)
            R1fastq=$i
            R2fastq="${fastq_dir}/${prefix}_2.fastq"
        elif [[ "${nameFormat}" == "FORMAT4" ]]
        then
            prefix=$(basename --suffix="_1${nameSuffix}.fastq.gz" $i)
            R1fastq=$i
            R2fastq="${fastq_dir}/${prefix}_2${nameSuffix}.fastq.gz"
        fi

        ## Run Cutadapt
        printf "\n\n#########  Running Cutadapt on data %s ...\n\n" ${prefix}
        cutadapt -j ${nthreads_per_task} \
                ${R1_AdaptersToTrim} ${R2_AdaptersToTrim} \
                -u "-${CutBases}" -U "-${CutBases}" \
                ${quality_opt} -m ${MinLength} \
                -o "${cutadapt_outdir}/${prefix}_R1.trimmed.fastq.gz" \
                -p "${cutadapt_outdir}/${prefix}_R2.trimmed.fastq.gz" \
                "${R1fastq}" "${R2fastq}" \
                &> ${cutadapt_outdir}/${prefix}.cutadapt.log &
                        ## The & at the end of the line starts this process in the background
                        ## to allow parallel processing.

        ## Pause the script if a specified max number of children processes
        ## are running in the background.
        nchild=$( pgrep -c -P$$ )
        echo "${nchild} child processes are running."; echo ""
        while [[ $nchild -ge $ntasks ]]; do
                sleep 1
                nchild=$( pgrep -c -P$$ )
        done
done

## For more information about cutadapt usage, check
##   https://cutadapt.readthedocs.io/en/stable/guide.html#basic-usage
## or run the command
##   $ cutadapt --help

## Wait for Cutadapt processes to finish before running fastqc
wait

fi  #### STEP 1 ends here



####################################################################
##  CONCATENATE FASTQ FILES FOR SAME SAMPLE FROM DIFFERENT LANES  ##
####################################################################

if [ ${StartingStep} -le 2 ]; then  #### STEP 2 starts here

## Get the unique list of file path prefixes for samples whose trimmed fastq file
## names end with "_L###_R1.trimmed.fastq.gz".

multilane_samples=$(ls ${cutadapt_outdir}/*_L[0-9][0-9][0-9]_R1.trimmed.fastq.gz \
    | sed "s/_L[0-9][0-9][0-9]_R1[.]trimmed[.]fastq[.]gz//" | uniq)

## Concatenate R1 fastq files from the same sample on different lanes, and then
## do the same for R2 fastq files.

for prefix in ${multilane_samples}
do
  	newname1="${prefix}_merged_R1.trimmed.fastq.gz"
        zcat ${prefix}_L[0-9][0-9][0-9]_R1.trimmed.fastq.gz | gzip > ${newname1}

        newname2="${prefix}_merged_R2.trimmed.fastq.gz"
        zcat ${prefix}_L[0-9][0-9][0-9]_R2.trimmed.fastq.gz | gzip > ${newname2}
done

fi  #### STEP 2 ends here



###########################################
##   RUN FASTQC ON TRIMMED FASTQ FILES   ##
###########################################

## Use the following command to install fastqc in a conda environment:
##  conda install -c bioconda fastqc

## fastqc options:
## -t : number of threads
## -o : output directory

## Create output directory for FastQC
fastqc_ver=$(fastqc --version | sed "s/FastQC v//")
fastqc_outdir="${cutadapt_outdir}/fastqc${fastqc_ver}"
if [ ! -d "${fastqc_outdir}" ]
then
        mkdir "${fastqc_outdir}"
fi

if [ ${StartingStep} -le 3 ]; then  #### STEP 3 starts here

## Run fastqc
printf "\n\n#########  Running FastQC ...\n\n"
fastqc -t "${nthreads}" -o "${fastqc_outdir}" ${cutadapt_outdir}/*.fastq.gz \
    &> ${fastqc_outdir}/fastqc.log

## Wait for fastqc before starting STAR
wait

fi  #### STEP 3 ends here



########################################
##  ALIGN READS TO GENOME USING STAR  ##
########################################

## Use the following command to install STAR in a conda environment
##  conda install -c bioconda star

## Determine folder path for STAR output
STAR_ver=$(STAR --version)
STAR_outdir="${cutadapt_outdir}/STAR${STAR_ver}_${RefGenome}"

if [ ${StartingStep} -le 4 ]; then  #### STEP 4	starts here

## Create output directory if it doesn't already exist
if [ ! -d "${STAR_outdir}" ]
then
        mkdir "${STAR_outdir}"
fi


######


## Run STAR in genome index generation mode first if the genome index 
## does not already exist.

if [ ! -d "${STAR_genomeDir}" ]
then
        mkdir "${STAR_genomeDir}"
fi

if [ ! -f "${STAR_genomeDir}/Genome" ]
then
        echo "Running STAR in genome index generation mode..."
        STAR --runMode genomeGenerate --runThreadN ${nthreads} \
                --genomeDir "${STAR_genomeDir}" \
                --genomeFastaFiles "${RefGenome_dir}/${RefGenome_fasta}" \
                --sjdbGTFfile "${annotationGTF}" \
                --sjdbOverhang $(( ${MaxReadLength} - 1 )) \
                &> ${STAR_outdir}/STAR.geneomeGenerate.log
        echo "Done generating genome indexes."
fi

wait


######


## Loop running STAR on R1/R2 fastq pairs
for i in ${cutadapt_outdir}/*R1.trimmed.fastq.gz
do
        prefix=$(basename --suffix="_R1.trimmed.fastq.gz" $i)
        R1fastq="${cutadapt_outdir}/${prefix}_R1.trimmed.fastq.gz"
        R2fastq="${cutadapt_outdir}/${prefix}_R2.trimmed.fastq.gz"
        printf "\nRunning STAR on fastq pair with prefix %s.\n" ${prefix}
        STAR --runMode alignReads --runThreadN ${nthreads_per_task} \
                --genomeDir "${STAR_genomeDir}" \
                --outSAMtype BAM Unsorted \
                --quantMode TranscriptomeSAM GeneCounts \
                --peOverlapNbasesMin 6 \
                --twopassMode Basic \
                --sjdbGTFfile "${annotationGTF}" \
                --readFilesCommand zcat \
                --readFilesIn "${R1fastq}" "${R2fastq}" \
                --outFileNamePrefix "${STAR_outdir}/${prefix}_" \
                &> ${STAR_outdir}/${prefix}.STAR.log &
                        ### Notes about STAR input options:
                        ### --sjdbGTFfile option not compatible with shared memory

        ## Pause the script if a specified max number of children processes
        ## are running in the background.
        nchild=$( pgrep -c -P$$ )
        echo "${nchild} child processes are running."; echo ""
        while [[ $nchild -ge $ntasks ]]; do
                sleep 1
                nchild=$( pgrep -c -P$$ )
        done
done

## Wait for all processes to finish
wait

## Remove genome from shared memory (if shared memory was use).
## Comment out the next line if no shared memory was used.
#STAR --genomeLoad Remove --genomeDir "${STAR_genomeDir}"

fi  #### STEP 4 ends here



##################################################################
##  MARK DUPLICATE FRAGMENTS and SORT BAM FILES using SAMTOOLS  ##
##################################################################

if [ ${StartingStep} -le 5 ]; then  #### STEP 5 starts here

## Use the following command to install samtools using conda
##   conda install -c bioconda samtools

## Get list of input BAM files
input_bam="${STAR_outdir}/*Aligned.out.bam"

for b in ${input_bam}
do
        ## Create file name for output BAM file.
        out_prefix="${b/%.out.bam}"

        ## Make sure reads are sorted or collated by name, then run fixmate.
        printf "\nRunning samtools collate then fixmate on %s.\n" $(basename $b)
       {
        samtools collate -@ ${nthreads_per_task} -O $b \
        | samtools fixmate -m -O BAM -@ ${nthreads_per_task} \
                - "${out_prefix}.collate.fixmate.bam"
       } &> ${out_prefix}.samtools.log &

        ## Pause the script if a specified max number of children processes
        ## are running in the background.
        nchild=$( pgrep -c -P$$ )
        echo "${nchild} child processes are running."; echo ""
        while [[ $nchild -ge $ntasks ]]; do
                sleep 1
                nchild=$( pgrep -c -P$$ )
        done
done

## Wait for all processes to finish
wait

## Get list of name-collated BAM files
collated_bam="${STAR_outdir}/*Aligned.collate.fixmate.bam"

for b in ${collated_bam}
do
        ## Create file name for output BAM file.
        out_prefix="${b/%.collate.fixmate.bam}"
        printf "\nout_prefix for samtools sort | markdup:\n   %s\n" ${out_prefix}

        ## Sort fixmate output BAM file by coordinate, then mark (but do not
        ## remove) duplicate fragments. Once done, delete the original 
        ## *Aligned.out.bam file as it will be redundant.
        printf "\nSorting %s by coords then marking duplicate fragments.\n" $(basename $b)
       {
        samtools sort -O BAM -@ ${nthreads_per_task} $b \
        | samtools markdup -d ${optical_dup_dist} --include-fails ${markdup_opts} \
                -c -f "${out_prefix}.markdup.stats" -O BAM -@ ${nthreads_per_task} \
                - "${out_prefix}.coordSort.markdup.bam"
        rm -fv ${out_prefix}.out.bam
       } &>> ${out_prefix}.samtools.log &

        ## Pause the script if a specified max number of children processes
        ## are running in the background.
        nchild=$( pgrep -c -P$$ )
        echo "${nchild} child processes are running."; echo ""
        while [[ $nchild -ge $ntasks ]]; do
                sleep 1
                nchild=$( pgrep -c -P$$ )
        done
done

## Wait for all processes to finish
wait

fi  #### STEP 5 ends here



#################################################
##  Perform QC of mapped reads using QUALIMAP  ##
#################################################


## Use the following command to install QualiMap in a Conda environment
##   conda install -c bioconda qualimap


## Set output directories for QualiMap

qualimap_outdir="${STAR_outdir}/QualiMap"
qualimap_NoDup_outdir="${STAR_outdir}/QualiMap_NoDup"

if [ ${StartingStep} -le 6 ]; then  #### STEP 6 starts here

if [ ! -d "${qualimap_outdir}" ]
then
        mkdir "${qualimap_outdir}"
fi

if [ ! -d "${qualimap_NoDup_outdir}" ]
then
    	mkdir "${qualimap_NoDup_outdir}"
fi


## Specify species for GC content comparison
if [[ "${RefGenome}" == "GRCh38" || "${RefGenome}" == "human" || "${RefGenome}" == "hg38" ]]
then
   ## Use this line for human:
        species="HUMAN"
elif [[ "${RefGenome}" == "GRCm38" || "${RefGenome}" == "mouse" ]]
then
   ## Use this line for mouse:
        species="MOUSE"
else
        echo "Invalid setting for RefGenome. Exiting."
        exit 1
fi

## Loop running QualiMap BAM QC and RNA-seq QC on BAM files output by STAR
export DISPLAY=""
for b in ${STAR_outdir}/*.coordSort.markdup.bam
do
        ## Generate prefix for file names.
        QMprefix=$(basename --suffix=".coordSort.markdup.bam" $b)
        printf "\nQualiMap input file prefix = %s\n" ${QMprefix}

        ## Run QualiMap bamqc without skipping duplicates.
        printf "Running QualiMap BAM QC (without skip-dup) on %s.\n" $(basename $b)
        qualimap bamqc -bam "$b" -nt ${nthreads_per_task} \
                --genome-gc-distr ${species} \
                --collect-overlap-pairs \
                -outdir "${qualimap_outdir}/${QMprefix}" \
                -outfile "${QMprefix}.qualimap.bamqc.report.pdf" \
                -outformat "HTML" \
                --java-mem-size=64G \
                &> "${qualimap_outdir}/${QMprefix}.qualimap.bamqc.log" &

        ## Pause the script if a specified max number of children processes
        ## are running in the background.
        nchild=$( pgrep -c -P$$ )
        echo "${nchild} child processes are running."; echo ""
        while [[ $nchild -ge $ntasks ]]; do
                sleep 1
                nchild=$( pgrep -c -P$$ )
        done

        ## Run QualiMap bamqc skipping duplicates.
        printf "Running QualiMap BAM QC (with skip-dup) on %s.\n" $(basename $b)
        qualimap bamqc -bam "$b" -nt ${nthreads_per_task} \
                --skip-duplicated \
                --genome-gc-distr ${species} \
                --collect-overlap-pairs \
                -outdir "${qualimap_NoDup_outdir}/${QMprefix}" \
                -outfile "${QMprefix}.qualimap.bamqc.NoDup.report.pdf" \
                -outformat "HTML" \
                --java-mem-size=64G \
                &> "${qualimap_NoDup_outdir}/${QMprefix}.qualimap.bamqc.NoDup.log" &

        ## Pause the script if a specified max number of children processes
        ## are running in the background.
        nchild=$( pgrep -c -P$$ )
        echo "${nchild} child processes are running."; echo ""
        while [[ $nchild -ge $ntasks ]]; do
                sleep 1
                nchild=$( pgrep -c -P$$ )
        done

        printf "Running QualiMap RNA-seq QC on %s ...\n" $(basename $b)
        qualimap rnaseq -bam "${b/.coordSort.markdup/.collate.fixmate}" -pe \
                -gtf "${annotationGTF}" \
                -outdir "${qualimap_outdir}/${QMprefix}" \
                -oc "${qualimap_outdir}/${QMprefix}.qualimap.rnaseq_counts" \
                -outfile "${QMprefix}.qualimap.rnaseq.report.pdf" \
                -outformat "HTML" \
                --java-mem-size=64G \
                &> "${qualimap_outdir}/${QMprefix}.qualimap.rnaseq.log" &

        ## Pause the script if a specified max number of children processes
        ## are running in the background.
        nchild=$( pgrep -c -P$$ )
        echo "${nchild} child processes are running."; echo ""
        while [[ $nchild -ge $ntasks ]]; do
                sleep 1
                nchild=$( pgrep -c -P$$ )
        done
done

## Wait for all processes to finish
wait

fi  #### STEP 6 ends here



#####################
##  FEATURECOUNTS  ##
#####################


## Use the following command to install Subread in a conda environment
##  conda install -c bioconda subread


## Determine path of subdir for featureCounts output
fc_outdir="${STAR_outdir}/featureCounts"

## Print the featureCounts version number to a txt file
featureCounts -v &> ${fc_outdir}/featureCounts_version.txt

## Get paths of BAM files
bam_paths="${STAR_outdir}/*.coordSort.markdup.bam"

## Create paths for output featureCounts files
fc_outpath="${fc_outdir}/featureCounts.${RefGenome}${outname_suffix}.txt"
fc_NoDup_outpath="${fc_outdir}/featureCounts_NoDup.${RefGenome}${outname_suffix}.txt"

if [ ${StartingStep} -le 7 ]; then  #### STEP 7 starts here

## Create subdir for featureCounts output if it doesn't already exist
if [ ! -d "${fc_outdir}" ]
then
    	mkdir "${fc_outdir}"
fi

## Strip "--ignoreDup" from featureCount options
opts=$(echo "${opts}" | sed -e "s/--ignoreDup//" -e "s/  / /")

## Run featureCounts, putting all results in a single table with each sample
## in a different column. Run once without skipping duplicate fragments and
## then again skipping duplicates.

printf "\nRunning featureCounts on all BAM files.\n"

logfilepath="${fc_outdir}/featureCounts.${RefGenome}${outname_suffix}.log"
featureCounts ${opts} -a ${annotationGTF} -o ${fc_outpath} ${bam_paths} &> ${logfilepath} &

printf "\n Running featureCounts --ignoreDup on all BAM files.\n"

logfilepath_NoDup="${fc_outdir}/featureCounts_NoDup.${RefGenome}${outname_suffix}.log"
featureCounts ${opts} --ignoreDup -a ${annotationGTF} -o ${fc_NoDup_outpath} ${bam_paths} \
    &> ${logfilepath_NoDup} &


if [ ${separate_featureCounts} = true ]
then
        printf "\nRunning featureCounts (with and without --ignoreDup) on individual BAM files.\n"

        ## Loop running featureCounts on each BAM file separately.
        for bam in ${bam_paths}
        do
            ## Pause the script if a specified max number of children processes
            ## are running in the background.
            nchild=$( pgrep -c -P$$ )
            echo "${nchild} child processes are running."; echo ""
            while [[ $nchild -ge $nthreads ]]; do
                    sleep 1
                    nchild=$( pgrep -c -P$$ )
            done

            ## Construct paths for featureCounts output files.
            fc_prefix=$(basename --suffix=".coordSort.markdup.bam" ${bam})
            fc_outpath="${fc_outdir}/${fc_prefix}.${RefGenome}.featureCounts.txt"
            fc_NoDup_outpath="${fc_outdir}/${fc_prefix}.${RefGenome}.featureCounts_NoDup.txt"

            ## Run featureCounts once without skipping duplicate fragments
            ## and then again while skipping duplicates.

            logfilepath="${fc_outdir}/${fc_prefix}.${RefGenome}.featureCounts.log"
            featureCounts ${opts} -a ${annotationGTF} -o ${fc_outpath} ${bam} \
                &> ${logfilepath} &

            ## Pause the script if a specified max number of children processes
            ## are running in the background.
            nchild=$( pgrep -c -P$$ )
            echo "${nchild} child processes are running."; echo ""
            while [[ $nchild -ge $nthreads ]]; do
                    sleep 1
                    nchild=$( pgrep -c -P$$ )
            done

            logfilepath_NoDup="${fc_outdir}/${fc_prefix}.${RefGenome}.featureCounts_NoDup.log"
            featureCounts ${opts} --ignoreDup -a ${annotationGTF} -o ${fc_NoDup_outpath} ${bam} \
                &> ${logfilepath_NoDup} &
        done
fi

## Wait for any background processes to finish
wait

fi  #### STEP 7 ends here



###############
##  MultiQC  ##
###############

## Directories for MultiQC reports.
multiqc_ver=$(multiqc --version | sed "s/multiqc, version //")
multiqc_outdir="${cutadapt_outdir}/MultiQC-${multiqc_ver}"
multiqc_NoDup_outdir="${cutadapt_outdir}/MultiQC-${multiqc_ver}_NoDup"

if [ ${StartingStep} -le 8 ]; then  #### STEP 8 starts here

## Create output directories if they don't already exist

if [ ! -d ${multiqc_outdir} ]
then
    	mkdir "${multiqc_outdir}"
fi

if [ ! -d ${multiqc_NoDup_outdir} ]
then
    	mkdir "${multiqc_NoDup_outdir}"
fi

printf "\nRunning MultiQC.\n"

## Run MultiQC ignoring de-duplicated QualiMap and featureCounts files.
multiqc -v -z \
    --ignore "*NoDup*" \
    --ignore "${qualimap_NoDup_outdir}/*" \
    -o ${multiqc_outdir} ${cutadapt_outdir} \
    &> ${multiqc_outdir}/multiqc.log

## Run MultiQC again, this time specifically for the de-duplicated files.
multiqc -v -z \
    --ignore "${qualimap_outdir}/*" \
    --ignore "*featureCounts.*" \
    -o ${multiqc_NoDup_outdir} ${cutadapt_outdir} \
    &> ${multiqc_NoDup_outdir}/multiqc.NoDup.log

fi  #### STEP 8 ends here




########################################################################
##  COPY THIS SCRIPT AND THE CONDA ENVIRONMENT INTO OUTPUT DIRECTORY  ##
########################################################################

## Create directory in which to save copies of bioinfo commands and
## conda environment.
bioinfo_dir="${fc_outdir}/bioinfo_pipeline"
if [ ! -d ${bioinfo_dir} ]
then
        mkdir "${bioinfo_dir}"
fi

cp -p $0 "${bioinfo_dir}/BioinfoCmd_rnaseq_counting_pipeline.txt"
chmod 755 "${bioinfo_dir}/BioinfoCmd_rnaseq_counting_pipeline.txt"

conda list --explicit > ${bioinfo_dir}/conda_env.txt



##################################################################
##  CREATE LIST OF ALL CREATED FILES and GENERATE SHA-2 HASHES  ##
##################################################################

## Create a new directory in which to save a list of all files generated
## and SHA-2 hash sums generated by sha256sum.

checksum_dir="${fastq_dir}/filenames_and_checksums"
if [ ! -d ${checksum_dir} ]
then
        mkdir "${checksum_dir}"
fi

## Get a list of all files in the output directory of CutAdapt and all
## subdirectories.
timestamp=$(date +%s)
find ${cutadapt_outdir}/ -exec printf '%s\n' '{}' \
    >> ${checksum_dir}/list_of_files.${timestamp}.txt ';'

## Generate SHA-2 hash sums for all files
for i in $(awk '{print $0;}' ${checksum_dir}/list_of_files.${timestamp}.txt);
do
        sha256sum "$i" >> ${checksum_dir}/SHA2_checksums.${timestamp}.sha256
done




#############################
#############################
####                     ####
####    END OF SCRIPT    ####
####                     ####
#############################
#############################
